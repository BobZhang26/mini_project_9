[![CI](https://github.com/BobZhang26/Bob_PythonTemplate1/actions/workflows/cicd.yml/badge.svg)](https://github.com/BobZhang26/Bob_PythonTemplate1/actions/workflows/cicd.yml)
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/{username}/{repository}/{branch}/{path})

## Week 9: Cloud-Hosted Notebook Data Manipulation

### summary 
In this mini project, we set up a cloud-hosted Jupyter Notebook and performed some data manipulation tasks on a sample dataset. 
This section delves into the creation and management of data pipelines using various cloud-hosted tools and platforms. The emphasis will be on PySpark, the Databricks Platform, and MLflow, each a critical tool in modern data engineering. Alongside these technical skills, we will explore principled leadership in teamwork and delve into management dynamics within teams. Manipulating data pipeline setup on Google colab is a first start. 

### Steps
1. Set up cloud-hosted environment (Google Colab)
2. Load bank customer churn data and perform data analysis including EDA, data cleaning, model construction, model analysis and data visulization.
3. Save colab form and link it to github
4. Set up standard github action to test the file


